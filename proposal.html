<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>WA - Proposal</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/browning.jpg" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=https://fonts.googleapis.com/css?family=Inconsolata:400,500,600,700|Raleway:400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">


</head>

<body>


  <nav class="navbar navbar-light custom-navbar">
    <div class="container">
      <a class="navbar-brand" href="index.html">Washieu Anan</a>

        <span></span>
      </a>
    </div>
  </nav>

  <main id="main">

    <section class="section">
      <div class="container">
        <div class="row mb-4 align-items-center">
          <div class="col-md-6" data-aos="fade-up">
            <h2>Proposal</h2>
            <p>Acheiving state-of-the-art localization via sensor fusion and moving-window Extended Kalman Filters.</p>
          </div>
        </div>
      </div>

      <div class="site-section pb-0">
        <div class="container">
          <div class="row align-items-stretch">
            <div class="col-md-8" data-aos="fade-up">
              <img src="assets/img/autopilot.jpg" alt="Image" class="img-fluid">
            </div>
            <br>
            &nbsp;
            <!-- <div class="col-md-8" data-aos="fade-up">
              <iframe width="650" height="400" src="https://www.youtube.com/embed/0t3wGQIypRg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div> -->
            <br>
            <div class="col-md-4 ml-auto" data-aos="fade-up" data-aos-delay="100">
              <div class="sticky-content">
                <h3 class="h3">Background</h3>
                <p class="mb-4"><span class="text-muted">Tesla</span></p>

                <div class="mb-5">
                  <p>Tesla Motors Company have successfully achieved state-of-the-art performance in the autonomous driving via their "autopilot" system. 
                    Their "autopilot" system is successful in navigating highway, city, and local roads, in various conditions. It does so solely through eight cameras and 12 ultrasonic sensors. 
                    Using advanced computer vision pipelines and deep learning models, Tesla Vehicles have the ability to detect lanes and nearby cars to determine the best possible path to its next waypoint/destination. 
                    While it is unknown what type of path follower/generator Tesla uses, it is widely understood that they use a combination of a PID (or MPC) Controller and Kalman Filters. 

                  </p>

                </div>

                <p class="mb-4"><span class="text-muted">FIRST Tech Challenge</span></p>

                <div class="mb-5">
                  <p>FIRST Tech Challenge robots, however, cannot achieve the same autonomous performance as Tesla Vehicles. The robots do not have the computing resources necessary to achieve full, deep-learning based
                    autonomous driving. The Control Hub, the main robot processor, has two cores and two threads. While multi-threading is possible, it is not reccomend in the FTC-context because resource-blocking, hardware-dependent calls to the LynxBoard (CPU).
                     It is, however, possible, to still have ultrasonic sensors and computer vision, albeit through standard OpenCV computer vision pipelines. 

                  </p>

                </div>

                <p class="mb-4"><span class="text-muted">Proposal</span></p>

                <div class="mb-5">
                  <p>
                    Considering the limitations that FTC Robots have, I propose using computer vision, four-wheel odometry, and ultrasonic sensors to achieve state-of-the-art localization. 
                    This means that the robot will be able to understand its position on the field with minimal amounts of error in both the autonomous and tele-operational period. 
                    While localization drift does not occur in the autonomous period because of its short time-frame, localization drift does occur in the tele-operational period. 
                    In the FTC Season Ultimate Goal, for example, it would be useful to not have localization drift as it would allow us to create an odometry-based auto-aiming system. 

                    Using the distance sensors and computer vision, I also plan on building obstacle subtraction algorithms, 
                    similar to the <a href="https://www.youtube.com/watch?v=0t3wGQIypRg">ones here.</a>
                    This would greatly improve our autonomous period as it would allow the robot to correct itself based on the un-planned obstacles on the field like another moving robot. 

                    I hope to achieve these goals through continous testing and experimentation over the summer of 2022 as outlined in my timeline below. <br><br> Currently, I am looking at the following research papers to assist me in my work:

                    <ul>
                      <li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.8890&rep=rep1&type=pdf">A Monocular Vision Sensor-Based Obstacle Detection Algorithm for Autonomous Robots</a></li>
                      <li><a href="https://arxiv.org/pdf/2107.08430v2.pdf">YOLOX: Exceeding YOLO Series in 2021</a></li>
                      <li><a href="https://arxiv.org/pdf/2002.06604v4.pdf">Key Points Estimation and Point Instance Segmentation Approach for Lane Detection</a></li>
                    </ul>
                  </p>

                </div>

                <h4 class="h4 mb-3">Timeline</h4>
                <ul class="list-unstyled list-line mb-5">
                  <li>Late June 2022 - 4 Wheel Odometry Localization</li>
                  <li>Early July 2022 - Odometry w/ Distance Sensor Fusion </li>
                  <li>Mid-July 2022 - Pure Pursuit Path Follower</li>
                  <li>Late-July 2022 - Low-Latency Object Detection Algorithms</li>
                  <li>Early-August 2022 - Odometry, Distance Sensor, Vision Fusion</li>
                  <li>Late-August 2022 - Object Subtraction Algorithms</li>
                  <li>To Be Updated</li>
                </ul>

                
              </div>
            </div>
          </div>
        </div>
    </section>


  <footer class="footer" role="contentinfo">
    <div class="container">
      <div class="row">
        <div class="col-sm-6">
          <p class="mb-1">&copy; Copyright Washieu Anan. All Rights Reserved</p>
          <div class="credits">
       
        
            Designed by <a href="https://github.com/washieuanan">Washieu Anan</a>
          </div>
        </div>

      </div>
    </div>
  </footer>

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>